\section{Visual Similarity}

Au coeur du problème de recommandation visuelle se trouve le choix d'une bonne similarité entre images, afin de classer
les résultats proposés ensuite. Pour cela, nous nous sommes basés sur l'utilisation de features extraites de modèles de
réseaux de neurones, que nous allons présenter ensuite.

\subsection{Extraction de features}

Le modèle le plus simple que nous avons utilisé est le réseau Inception V3 \cite{rethinking2015szegedy}, qui est une
architecture de réseau de neurones relativement légère et efficiente d'un point de vue computationnelle qui se situe
dans l'état de l'art en classification sur le dataset ImageNet \cite{imagenet_cvpr09}.

Nous appliquons cette architecture sur notre base de données afin de récupérer les vecteurs de features de nos images,
et nous utilisons différentes métriques pour mesurer les similarités entre paires d'images.

\subsubsection{Distance euclidienne}

Afin de mesurer la similarité entre deux images, nous nous sommes d'abord intéressés à la distance euclidienne entre
deux vecteurs, définie comme cela :
\begin{equation}
    d_{\text{eucl}} = \norm{x_1 - x_2}_2 = \sqrt{\sum_{i=1}^n (x_{1,i} - x_{2,i})^2}
\end{equation}

où $x_1, x_2$ représentent les features extraites à l'aide d'Inception v3, $n$ la taille de ces features, et $x_{\cdot,
i}$ la composante $i$ du vecteur $x_{\cdot}$.

\subsubsection{Similarité cosinus}

Nous avons ensuite utilisé la similarité cosinus entre deux vecteurs :
\begin{equation}
    \simcos (x_1, x_2) = \frac{x_1 \cdot x_2}{\norm{x_1}_2 \norm{x_2}}
\end{equation}

Les valeurs de $\simcos$ appartiennent à $\left[-1, 1\right]$. La valeur $1$ indique que les vecteurs sont égaux, $0$
que les vecteurs sont décorrélés, et $-1$ que les vecteurs sont négativement corrélés. Les valeurs intermédiaires
mesurent le degré de similarité entre les vecteurs considérés.

\subsubsection{Distance Hamming}

Enfin, nous avons binarisé nos features, et utilisé une distance de Hamming pour mesurer les performances

\subsection{R\'eseaux Siamois}

Les réseaux siamois sont une architecture introduite pour la première fois par \cite{signature1993bromley}. Cette
architecture apprend à déterminer si deux images sont similaires ou non. Elle a d'abord été utilisé pour déterminer si
deux signatures étaient identiques. Nous représentons l'architecture que nous utilisons dans la figure
\ref{fig:siamese_arch}.

On prend une paire d'images appartenant ou non à la même classe, et on extrait de chaque image un vecteur de feature
avec le même DNN (Deep Neural Network). Dans notre cas, nous avons utilisé Inception V3 sans la dernière couche. On
soustrait ensuite les deux vecteurs avant de leur appliquer la fonction valeur absolue. On applique ensuite au résultat
une Fully Connected Layer (FCN) pour réduire la taille de l'embedding, puis une sigmoïde qui donne la probabilité que
les deux images appartiennent à la même classe.

Pour extraire les features de notre réseau siamois entrainé, nous récupérons les poids $W$ et $b$ de la couche FCN. Nous
utilisons le DNN utilisé par le réseau siamois pour extraire une feature $x$ d'une image, puis nous calculons $Wx + b$
pour obtenir la feature finale.

\begin{figure}[ht]
    \center
    \includegraphics[width = 0.8\textwidth]{figures/siamese_arch.pdf}
    \caption{\label{fig:siamese_arch} \textbf{Architecture d'un r\'eseau siamois}}
\end{figure}

\subsection{R\'eseaux Triplets}

Nous avons aussi essayé d'utiliser un \textit{réseau triplet}, qui ont été introduits pour la première fois par
\cite{hoffer2014deep}.

\begin{figure}[ht]
    \center
    \includegraphics[width = 0.6\textwidth]{figures/triplet_arch.pdf}
    \caption{\label{fig:siamnet_arch} \textbf{Architecture d'un réseau triplet}}
\end{figure}

Les réseaux triplets sont une amélioration des réseaux siamois déjà susmentionnés. À chaque itération, le nombre
d'images en entrée est de 3 : 

\begin{itemize}
    \item image de base (anchor)
    \item image similaire (positive)
    \item image différente (negative)
\end{itemize}

Cela revient à ajouter un nouveau terme dans la fonction de perte du modèle. Cet ajout permet 
