{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.layers import UpSampling2D, Input\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define SiameseNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define model\n",
    "\n",
    "# Load ResNet NN and keep only the relevant layers\n",
    "\n",
    "#TODO: add dropout\n",
    "\n",
    "#resnet = ResNet50(weights='imagenet', include_top=True)\n",
    "resnet = ResNet50(weights=None, include_top=True)\n",
    "resnet.layers.pop()\n",
    "resnet.outputs = [resnet.layers[-1].output]\n",
    "resnet.layers[-1].outbound_nodes = []\n",
    "\n",
    "# Def right and left inputs\n",
    "left_img = Input(shape=(32, 32, 3), name='left_input')\n",
    "right_img = Input(shape=(32, 32, 3), name='right_input')\n",
    "left_inp = UpSampling2D(size =(7,7))(right_img)\n",
    "right_inp = UpSampling2D(size =(7,7))(left_img)\n",
    "\n",
    "# Def model\n",
    "left_out = resnet(left_inp)\n",
    "right_out = resnet(right_inp)\n",
    "diff = keras.layers.subtract([left_out, right_out])\n",
    "prediction = keras.layers.Dense(1,activation='sigmoid', name='dist')(diff)\n",
    "siamese_net = Model(input=[left_img,right_img],output=prediction)\n",
    "\n",
    "# Compile model\n",
    "adadelta = keras.optimizers.Adadelta()\n",
    "siamese_net.compile(loss='binary_crossentropy', optimizer=adadelta)\n",
    "\n",
    "# Print information about the model\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ResNet weight fine tuned\n",
    "resnet_tuned = siamese_net.layers[4]\n",
    "img = Input(shape=(32, 32, 3), name='input')\n",
    "img2 = UpSampling2D(size =(7,7))(img)\n",
    "\n",
    "# Def model\n",
    "feat = resnet_tuned(img2)\n",
    "extractor = Model(input=img, output=feat)\n",
    "extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom distance for our k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract distance layer from our model, and use it for the k-NN\n",
    "dist_layer = siamese_net.get_layer('dist').get_weights()\n",
    "def cust_dist(x, y):\n",
    "    \"\"\"Distance using the metric learned by our SiameseNet\n",
    "    Args:\n",
    "        x, y: (array (2048,)): the features to use\n",
    "    return:\n",
    "        dist: (float) distance value\n",
    "    \"\"\"\n",
    "    temp = np.abs(x-y)\n",
    "    return np.dot(dist_layer, temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = [0,1,8,9]\n",
    "animal = [2,3,4,5,6,7]\n",
    "# Function to load a batch into memory\n",
    "def load_batch(data_dir, batch_id):\n",
    "    with open(os.path.join(data_dir, 'data_batch_%i' % batch_id), mode='rb') as file:\n",
    "        batch = pk.load(file, encoding='latin1')\n",
    "    feats = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    lbls = batch['labels']\n",
    "    return feats, lbls\n",
    "\n",
    "# Generate pairs according to a certain percentage\n",
    "def get_pairs(data_path, positive_percentage=0.5, cifar_batch_id=1, batch_size=32, plt_fig=False):\n",
    "    left = []\n",
    "    right = [] \n",
    "    feats, labels = load_batch(data_path, cifar_batch_id)\n",
    "    indexes = np.random.randint(len(labels),size=batch_size)\n",
    "    sample_images = np.take(feats, indexes, axis=0)\n",
    "    sample_labels = np.take(labels, indexes, axis=0)\n",
    "    other_indexes = np.delete(range(len(labels)), indexes)\n",
    "    other_feats = np.take(feats, other_indexes, axis=0)\n",
    "    other_labels = np.take(labels, other_indexes)\n",
    "    for i in range(batch_size):\n",
    "        if i < int(batch_size*positive_percentage):\n",
    "            index_of_label = np.where(other_labels==sample_labels[i])[0]\n",
    "        else :\n",
    "            if sample_labels[i] in machine:\n",
    "                machine_without = machine.copy()\n",
    "                machine_without.remove(sample_labels[i])\n",
    "                index_of_label = np.where(np.isin(other_labels, machine_without))[0]\n",
    "            else : \n",
    "                animal_without = animal.copy()\n",
    "                animal_without.remove(sample_labels[i])\n",
    "                index_of_label = np.where(np.isin(other_labels, animal_without))[0]\n",
    "        index = np.take(index_of_label, np.random.randint(len(index_of_label)))\n",
    "        other_image = other_feats[index]\n",
    "        if plt_fig:\n",
    "            plt.figure()\n",
    "            plt.subplot(\"121\")\n",
    "            plt.imshow(other_image)\n",
    "            plt.subplot(\"122\")\n",
    "            plt.imshow(sample_images[i])\n",
    "        left.append(sample_images[i])\n",
    "        right.append(other_image)\n",
    "        \n",
    "    #Generate pair labels\n",
    "    y = np.zeros(batch_size)\n",
    "    for i in range(int(batch_size*positive_percentage)):\n",
    "        y[i] = 1\n",
    "        \n",
    "    return [np.array(left), np.array(right)], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create toy dataset (to be improved)\n",
    "data_path = '../data/cifar10/'\n",
    "dataset = [[], []]\n",
    "dataset_labels = []\n",
    "cifar_batch_id = [1, 2, 3, 4 , 5]\n",
    "nb_pairs_per_batch = 10000\n",
    "for batch in cifar_batch_id:\n",
    "    data, y = get_pairs(data_path, 0.5, 1, batch_size=20000)\n",
    "    dataset[0] += [data[0]]\n",
    "    dataset[1] += [data[1]]\n",
    "    dataset_labels += [y]\n",
    "dataset[0] = np.concatenate(dataset[0])\n",
    "dataset[1] = np.concatenate(dataset[1])\n",
    "dataset_labels = np.concatenate(dataset_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese Networks training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net.fit(dataset, dataset_labels, epoch=10, metrics=[\"accuracy\"], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
